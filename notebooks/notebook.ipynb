{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b003e82-a9bc-4cb2-82ad-9b70b2bf3cb2",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding:10px; border:1px solid #ccc; border-radius:5px; font-size:30px;\">\n",
    "Overview\n",
    "</div>\n",
    "\n",
    "This notebook demonstrates a simple end-to-end pipeline for converting PDF documents into searchable vector representations using FAISS and multilingual sentence embeddings.\n",
    "\n",
    "Workflow:\n",
    "- Extract text from PDF files\n",
    "- Generate sentence embeddings with a multilingual model\n",
    "- Store vectors in a FAISS index\n",
    "- Perform semantic search using a natural language query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8f67b-5081-4f4b-a5a6-e5df73153f60",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding:10px; border:1px solid #ccc; border-radius:5px; font-size:30px;\">\n",
    "Indexing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a16e86-2ee0-4431-8f38-4a495f38fced",
   "metadata": {},
   "source": [
    "### Extracting Text from PDF\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280c30f6-ace4-47b5-a0e0-143090ec91ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDF files: 4\n",
      "chatbot_ip_protection-EA0125007ENN.pdf: 1 chunks extracted\n",
      "CN-2023-0012.pdf: 2 chunks extracted\n",
      "adth-5th Edition-2024.pdf: 101 chunks extracted\n",
      "a-short-guide.pdf: 12 chunks extracted\n",
      "\n",
      "Total number of chunks: 116\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import pdfplumber\n",
    "\n",
    "# Suppress pdfminer warnings\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# Directory containing PDF files\n",
    "pdf_dir = \"../data/input/pdf/\"\n",
    "pdf_files = glob.glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
    "\n",
    "print(f\"Number of PDF files: {len(pdf_files)}\")\n",
    "\n",
    "# List to store all extracted chunks\n",
    "all_chunks = []\n",
    "\n",
    "# Process each PDF file\n",
    "for file_path in pdf_files:\n",
    "    chunk_count = 0\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    all_chunks.append({\n",
    "                        \"chunk_id\": f\"{os.path.basename(file_path)}_page_{i+1}\",\n",
    "                        \"text\": text.strip(),\n",
    "                        \"page\": i + 1,\n",
    "                        \"file_path\": file_path,\n",
    "                    })\n",
    "                    chunk_count += 1\n",
    "        print(f\"{os.path.basename(file_path)}: {chunk_count} chunks extracted\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {os.path.basename(file_path)}: {e}\")\n",
    "\n",
    "# Summary of total chunks\n",
    "print(f\"\\nTotal number of chunks: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd65f133-7243-4041-ab64-a92533a3e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First chunk - page 1 (chatbot_ip_protection-EA0125007ENN.pdf):\n",
      "\n",
      "CASE STUDY Chatbot IP Protection\n",
      "Background\n",
      "The Swedish start-up Poseidon owns the word trade mark in Sweden. They specialise in AI-based B2B manufacturing services. The company\n",
      "uses a specially trained chatbot to meet the needs of its customers and has a particular method for carrying out its activ\n"
     ]
    }
   ],
   "source": [
    "# Preview the first chunk if available\n",
    "first = all_chunks[0]\n",
    "print(f\"\\nFirst chunk - page {first['page']} ({os.path.basename(first['file_path'])}):\\n\")\n",
    "print(first['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a3f855-7fbd-4f3b-94f3-2b33d12a7b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatbot_ip_protection-EA0125007ENN.pdf_page_1</td>\n",
       "      <td>CASE STUDY Chatbot IP Protection\\nBackground\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/input/pdf/chatbot_ip_protection-EA0125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-2023-0012.pdf_page_1</td>\n",
       "      <td>A Simple PDF File\\nCN-2023-0012\\nThis is a sma...</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/input/pdf/CN-2023-0012.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN-2023-0012.pdf_page_2</td>\n",
       "      <td>Simple PDF File 2\\n...continued from page 1. Y...</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/input/pdf/CN-2023-0012.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adth-5th Edition-2024.pdf_page_1</td>\n",
       "      <td>A\\nIRSIDE\\nD\\nT h e o r y\\nRIVING\\nH a n d b o...</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/input/pdf/adth-5th Edition-2024.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adth-5th Edition-2024.pdf_page_2</td>\n",
       "      <td>A\\nIRSIDE\\nD\\nT h e o r y\\nRIVING\\nH a n d b o...</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/input/pdf/adth-5th Edition-2024.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>a-short-guide.pdf_page_8</td>\n",
       "      <td>A SHORT GUIDE\\n6.\\nWashrooms\\nThere are washro...</td>\n",
       "      <td>8</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>a-short-guide.pdf_page_9</td>\n",
       "      <td>A SHORT GUIDE\\n8. We Are Here To Help\\nWe have...</td>\n",
       "      <td>9</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>a-short-guide.pdf_page_10</td>\n",
       "      <td>A SHORT GUIDE\\n9.\\nReduced Mobility Assistance...</td>\n",
       "      <td>10</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>a-short-guide.pdf_page_11</td>\n",
       "      <td>A SHORT GUIDE\\nDublin Airport Short and Long T...</td>\n",
       "      <td>11</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>a-short-guide.pdf_page_12</td>\n",
       "      <td>A SHORT GUIDE\\nDublin Airport Terminals Map\\nG...</td>\n",
       "      <td>12</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          chunk_id  \\\n",
       "0    chatbot_ip_protection-EA0125007ENN.pdf_page_1   \n",
       "1                          CN-2023-0012.pdf_page_1   \n",
       "2                          CN-2023-0012.pdf_page_2   \n",
       "3                 adth-5th Edition-2024.pdf_page_1   \n",
       "4                 adth-5th Edition-2024.pdf_page_2   \n",
       "..                                             ...   \n",
       "111                       a-short-guide.pdf_page_8   \n",
       "112                       a-short-guide.pdf_page_9   \n",
       "113                      a-short-guide.pdf_page_10   \n",
       "114                      a-short-guide.pdf_page_11   \n",
       "115                      a-short-guide.pdf_page_12   \n",
       "\n",
       "                                                  text  page  \\\n",
       "0    CASE STUDY Chatbot IP Protection\\nBackground\\n...     1   \n",
       "1    A Simple PDF File\\nCN-2023-0012\\nThis is a sma...     1   \n",
       "2    Simple PDF File 2\\n...continued from page 1. Y...     2   \n",
       "3    A\\nIRSIDE\\nD\\nT h e o r y\\nRIVING\\nH a n d b o...     1   \n",
       "4    A\\nIRSIDE\\nD\\nT h e o r y\\nRIVING\\nH a n d b o...     2   \n",
       "..                                                 ...   ...   \n",
       "111  A SHORT GUIDE\\n6.\\nWashrooms\\nThere are washro...     8   \n",
       "112  A SHORT GUIDE\\n8. We Are Here To Help\\nWe have...     9   \n",
       "113  A SHORT GUIDE\\n9.\\nReduced Mobility Assistance...    10   \n",
       "114  A SHORT GUIDE\\nDublin Airport Short and Long T...    11   \n",
       "115  A SHORT GUIDE\\nDublin Airport Terminals Map\\nG...    12   \n",
       "\n",
       "                                             file_path  \n",
       "0    ../data/input/pdf/chatbot_ip_protection-EA0125...  \n",
       "1                   ../data/input/pdf/CN-2023-0012.pdf  \n",
       "2                   ../data/input/pdf/CN-2023-0012.pdf  \n",
       "3          ../data/input/pdf/adth-5th Edition-2024.pdf  \n",
       "4          ../data/input/pdf/adth-5th Edition-2024.pdf  \n",
       "..                                                 ...  \n",
       "111                ../data/input/pdf/a-short-guide.pdf  \n",
       "112                ../data/input/pdf/a-short-guide.pdf  \n",
       "113                ../data/input/pdf/a-short-guide.pdf  \n",
       "114                ../data/input/pdf/a-short-guide.pdf  \n",
       "115                ../data/input/pdf/a-short-guide.pdf  \n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_chunks)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff180a2-7686-4371-aad7-8a4067895177",
   "metadata": {},
   "source": [
    "## Embedding Text into Vectors\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33902202-2b0f-432c-9b92-af88fe2bc349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/search-vector-semantic-files/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDF files: 4\n",
      "CN-2023-0012.pdf: extracted 2 pages\n",
      "a-short-guide.pdf: extracted 12 pages\n",
      "adth-5th Edition-2024.pdf: extracted 101 pages\n",
      "chatbot_ip_protection-EA0125007ENN.pdf: extracted 1 pages\n",
      "Total number of chunks: 116\n",
      "FAISS index size: 116 vectors\n",
      "Saved FAISS index to: ../data/faiss/faiss.index\n",
      "Saved metadata to: ../data/faiss/faiss_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import pickle\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define input and output paths\n",
    "pdf_dir = Path(\"../data/input/pdf\")\n",
    "index_path = Path(\"../data/faiss/faiss.index\")\n",
    "meta_path = Path(\"../data/faiss/faiss_meta.pkl\")\n",
    "index_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load multilingual embedding model (supports Japanese and English)\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-small\")\n",
    "\n",
    "# Collect all PDF file paths\n",
    "pdf_paths = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "print(f\"Number of PDF files: {len(pdf_paths)}\")\n",
    "\n",
    "# Extract text chunks from PDFs\n",
    "all_chunks = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    all_chunks.append({\n",
    "                        \"chunk_id\": f\"{pdf_path.name}_page_{i+1}\",\n",
    "                        \"text\": text.strip(),\n",
    "                        \"page\": i + 1,\n",
    "                        \"file_path\": str(pdf_path)\n",
    "                    })\n",
    "        print(f\"{pdf_path.name}: extracted {len(pdf.pages)} pages\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path.name}: {e}\")\n",
    "\n",
    "print(f\"Total number of chunks: {len(all_chunks)}\")\n",
    "\n",
    "# Encode text to embeddings\n",
    "texts = [chunk[\"text\"] for chunk in all_chunks]\n",
    "embeddings = model.encode(texts, normalize_embeddings=True)\n",
    "\n",
    "# Add embedding vectors to each chunk\n",
    "for chunk, emb in zip(all_chunks, embeddings):\n",
    "    chunk[\"embedding\"] = emb\n",
    "\n",
    "# Create and populate FAISS index\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "vecs = np.array([chunk[\"embedding\"] for chunk in all_chunks]).astype(\"float32\")\n",
    "index.add(vecs)\n",
    "\n",
    "print(f\"FAISS index size: {index.ntotal} vectors\")\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, str(index_path))\n",
    "print(f\"Saved FAISS index to: {index_path}\")\n",
    "\n",
    "# Remove embeddings from metadata to reduce size\n",
    "for chunk in all_chunks:\n",
    "    chunk[\"embedding\"] = None\n",
    "\n",
    "# Save chunk metadata as pickle\n",
    "with open(meta_path, \"wb\") as f:\n",
    "    pickle.dump(all_chunks, f)\n",
    "\n",
    "print(f\"Saved metadata to: {meta_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8865c-72c9-4114-82cd-22cf34a59813",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding:10px; border:1px solid #ccc; border-radius:5px; font-size:30px;\">\n",
    "Semantic Search\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e40044-6135-4b7e-85d1-6e86da72ea41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>file_path</th>\n",
       "      <th>text_preview</th>\n",
       "      <th>score_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "      <td>A Short Guide\\nDublin Airport can be a busy pl...</td>\n",
       "      <td>0.287889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "      <td>A SHORT GUIDE\\nDublin Airport Short and Long T...</td>\n",
       "      <td>0.303969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "      <td>Contents\\n1. Finding Your Way Around\\n2. Arriv...</td>\n",
       "      <td>0.311374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>../data/input/pdf/a-short-guide.pdf</td>\n",
       "      <td>A SHORT GUIDE\\n8. We Are Here To Help\\nWe have...</td>\n",
       "      <td>0.334602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>../data/input/pdf/adth-5th Edition-2024.pdf</td>\n",
       "      <td>Contents\\nSECTION I Introduction\\n1. Introduct...</td>\n",
       "      <td>0.341540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                                    file_path  \\\n",
       "0     2          ../data/input/pdf/a-short-guide.pdf   \n",
       "1    11          ../data/input/pdf/a-short-guide.pdf   \n",
       "2     3          ../data/input/pdf/a-short-guide.pdf   \n",
       "3     9          ../data/input/pdf/a-short-guide.pdf   \n",
       "4     3  ../data/input/pdf/adth-5th Edition-2024.pdf   \n",
       "\n",
       "                                        text_preview  score_l2  \n",
       "0  A Short Guide\\nDublin Airport can be a busy pl...  0.287889  \n",
       "1  A SHORT GUIDE\\nDublin Airport Short and Long T...  0.303969  \n",
       "2  Contents\\n1. Finding Your Way Around\\n2. Arriv...  0.311374  \n",
       "3  A SHORT GUIDE\\n8. We Are Here To Help\\nWe have...  0.334602  \n",
       "4  Contents\\nSECTION I Introduction\\n1. Introduct...  0.341540  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load FAISS index and metadata\n",
    "index_path = \"../data/faiss/faiss.index\"\n",
    "meta_path = \"../data/faiss/faiss_meta.pkl\"\n",
    "\n",
    "index = faiss.read_index(index_path)\n",
    "\n",
    "with open(meta_path, \"rb\") as f:\n",
    "    chunks = pickle.load(f)\n",
    "\n",
    "# Load embedding model (multilingual)\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-small\")\n",
    "\n",
    "# Define search query\n",
    "query_text = \"I’d like to know about airport\"\n",
    "\n",
    "# Encode the query to an embedding vector\n",
    "query_vec = model.encode([query_text], normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "# Search top-k results in FAISS index\n",
    "top_k = 5\n",
    "distances, indices = index.search(query_vec, top_k)\n",
    "\n",
    "# Format results\n",
    "results = []\n",
    "for idx, dist in zip(indices[0], distances[0]):\n",
    "    if idx < len(chunks):\n",
    "        results.append({\n",
    "            \"page\": chunks[idx][\"page\"],\n",
    "            \"file_path\": chunks[idx][\"file_path\"],\n",
    "            \"text_preview\": chunks[idx][\"text\"][:150] + \"...\",\n",
    "            \"score_l2\": float(dist)\n",
    "        })\n",
    "\n",
    "\n",
    "# Convert results to DataFrame for display\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa355e-67b0-42e8-8d38-66a54d385739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
